<!doctype html>
<html lang="en">

	<head>
    <meta charset="utf-8">

    <title>JCES - Philosophy and film</title>

    <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
    <meta name="author" content="Hakim El Hattab">

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/black.css" id="theme">
    <link rel="stylesheet" href="css/estilo.css">


    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
</head>

<body>

    <div class="reveal">

        <!-- Any section element inside of this container is displayed as a slide -->
        <div class="slides">


<section  data-background-image ="img/ai.jpg"data-background-size = "cover">
    <h1><br></h1>
    	<h2 class="highlightred">Artificial minds?</h2> 

    	<font size="3"><p class="highlightred">Juan Camilo Espejo-Serna<br> Universidad de la Sabana</p></font> 

 
    

</section>

<section>
Public service announcement: On International Women's Day        
    
    <h1 class="fragment">Why?</h1>
            </section>        
<!--
            
            
<section>
    <font size="6">
2012: Rosa Elvira Cely sold sweets and stuff on the street in front of the Military Hospital, had a 11-year-old daughter, and was finishing her high school studies, wishing to become a psychologist. One night walking back home with a classmate, she was repeatedly beaten, violently abused and raped, impaled with a tree branch and left to die next in the National Park in Bogotá.
    
    <p class="fragment">This is not uncommon. Many women are violently attacked by the people who purportedly are romantically interested in them. 
    </p>
    
    <p class="fragment">Please do not think of international women's day as an occassion to give flowers to the women in your life, as one might do on teacher's day.</p>
    
    
    </font>
            
            </section>        
-->
                        

<section><h2>Plan</h2>
<ol>
<li class="fragment fade-up">Film overview</li>

<li class="fragment fade-up"><a href="#/dos">Turing's Test</a></li>
<li class="fragment fade-up"><a href="#/cuatro">Should we be wary?</a></li>
	


</ol>

</section>  
                
                
<section  data-background-image ="img/ai.jpg" data-background-size = "auto">
                <h2 class="highlightred">Film overview</h2>
            </section>

            
            <section data-transition="fade-in">
 <p class="doscuadros">Write in chat a one-line summary of the plot of EX-MACHINA.</p>
                <p class="fragment doscuadros">(A good one :P).</p>
                <img src="img/ai1.gif" style="max-height:  400px">
               

            </section>



            <section data-transition="slide-in fade-out">

                The film considers several topics of philosophical interest revolving around the nature of the mind <span class="fragment">and what we have to fear about AI</span>
            </section>
            
            
<section data-auto-animate>
    <h2>The film seems to take the view that we shold be wary of AI because of its cold rationality.</h2>
                
                </section>    
            
                        
            
<section>Main claim:
    
    <br> Nathan: Ava was a mouse in a mousetrap.
And I gave her one way out. To escape, she would have to use imagination, sexuality, self-awareness, empathy, manipulation - and she did. If that isn’t AI, what the fuck is?
            
            </section>                
                
            
                
<section  data-background-image ="img/ai.jpg" data-background-size = "auto">
                <h2 class="highlightred">Turing's Test</h2>
            </section>            
                
<section>
<video data-autoplay  class="stretch" src="videos/ai.mp4"></video></section>
                
<section>
            
           This is not quite right but almost. 

            </section>  
    <section>
        To to talk about artificial intelligence, it is important to determine the terms more precisely. In many cases an intuitive understanding of what artificial intelligence is used without a strong theoretical characterization of what it is.

            </section>          
<section>When talking about AI we usually think about images from science fiction.</section> 
                
<section>One of the main difficulties in trying to offer a characterization of artificial intelligence is that we do not have a good idea of what natural intelligence is either. 
            
<p class="fragment">Since we have no sold idea of what human and animal intelligence is, how can we begin to define  <em>artificial</em> intelligence?</p>
            </section> 
             
<section>Alan Turing proposed a brilliant workaround.
            
            <p class="fragment">He proposed an empirical test, not a conceptual definition.</p>

            </section> 

<section>The general idea is simple but powerful: if there is a human activity that requires intelligences and a machine can perform sucessfully such activity, then we can say that the machine can think.</section> 

<section>
    <font size="6">
    "I propose to consider the question, ' Can machines think ? ' This should begin with definitions of the meaning of the terms 'machine' and 'think'. The definitions might be framed so as to reflect so far as possible the normal use of the words, but this attitude is dangerous. If the meaning of the words 'machine' and 'think' are to be found by examining how they are commonly used it is difficult to escape the conclusion that the meaning and the answer to the question, 'Can machines think?' is to be sought in a statistical survey such as a Gallup poll. But this is absurd. Instead of attempting such a definition I shall replace the question by another, which is closely related to it and is expressed in relatively unambiguous words." (Turing 1950, 433)</font></section>            
            
<section>
             <font size="6">
                 The new form of the problem can be described in terms of a game which we call the 'imitation game'. It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart from the other two. The object of the game for the interrogator is to determine which of the other two is the man and which is the woman. He knows them by labels X and Y, and at the end of the game he says either ' X is A and Y is B ' or ' X is B and Y is A'. (Turing 1950, 433)</font>
            </section>            
<section>
               <font size="6">
                   We now ask the question, 'What will happen when a machine takes the part of A in this game?' Will the interrogator decide wrongly as often when the game is played like this as he does when the game is played between a man and a woman? These questions replace our original, 'Can machines think ?' (Turing 1950, 434)</font>

            </section>            
            
<section>
The issue Turing is talking about is thought, not consciousness. Whether consciousness comes together with a general capacity for thought is a question that should be distinguished. <br> The film mixes them up.</section> 
           
    <section>  Consciousness might refer to either the phenomenally conscious aspect of what it is like to be in a given state or the availability for use in reasoning and rationally, guiding speech and action.
        
        
</section>        

            
    <section><em>IF</em> these come apart, we might have beings with the capacity for thought without the capacity for consciousness and the other way round.</section>    
            
                <section>Some philosophers  think that it is possible to have (phenomenal) consciousness without thought: a mind that have a distinct feel but without the capacity think properly. <span class="fragment"> (Like an octopus, for example. )</span></section>        

                            <section>Some philosophers  think that it is possible to have thought without consciousness: a mind that can have rational thought without a distinctive qualitative feel. <span class="fragment"> (They are often referred to as "philosophical zombies". AI  is usually portrayed in this way. )</span></section>        

<section>
   Turing seems to suggest that we have AI when we get the rational engagement needed in order to fool a judge into thinking that it is a human speaking. But as I have said, the idea more generally seems to be that when machines behave in a way in which we cannot distinguish from intelligent behaviour, then we have there genuine intelligence.
    
    
    <p class="fragment">There are two problems with this suggestion</p>
   
</section>
            
<section>
    The first problem is empirical.
        <p class="fragment">We have already machines that perform at the highest levels of competence but we do not have AI.</p>

    
</section>            
       
            <section data-background-image="img/kasparov.jpg" data-background-size="cover">
                <p style="background-color: rgba(0, 0, 0, 0.8)"></p>
            </section>
            <section> Towards the end of the XX century we got a machine that played chess at the highest levels of competence but  could not perform similarly in any other area. </section>

            <section data-background-image="img/aiwinter.jpg" data-background-size="cover">
                <p style="background-color: rgba(109, 109, 109, 0.65)">With this came the "AI winter"</p>

                <p class="fragment doscuadros" style="background-color: rgba(109, 109, 109, 0.65)">Less media attention </p>
                <p class="fragment doscuadros" style="background-color: rgba(109, 109, 109, 0.65)">Less military funding </p>
                <p class="fragment doscuadros" style="background-color: rgba(109, 109, 109, 0.65)">Less research</p>

            </section>
       
<section>
            
The second problem is theoretical.
            
                    <p class="fragment">It is possible to behave as if there were understanding without there being any.</p>

            </section> 
            
    <section>The film does not really stick to Turing's characterization of intelligence and rather suggests:
            
             <br> Nathan: Ava was a mouse in a mousetrap.
And I gave her one way out. To escape, she would have to use imagination, sexuality, self-awareness, empathy, manipulation - and she did. If that isn’t AI, what the fuck is?
            </section>        
            
                     <section data-background-image="img/chineseroom.jpg" data-background-size="cover">
</section>
  
   
<section  data-background-image ="img/ai.jpg" data-background-size = "auto">
                <h2 class="highlightred">Should we be wary?</h2>
</section>            

            
<section>The film presents the nearby future and suggests that we should be wary of it.
            </section>            

<section>The film seems to present the following picture: If we are cruel to the machines (like Nathan), they will kill us. If we are kind to the machines (like Caleb), they will use us. So, watch out for the machines!</section>            
            
<section>We are not quite in the future that the film presents. But should we worry?</section>     
            
<section>We need to understand better, actually looking at the developments and not taking our ideas from sci-fi.</section>
            
<section><h2>Rule following vs neural networks</h2></section>         
            
            
            
<section>One of the best examples of rule-following AI is Deep Blue</section>     
<section><iframe width="1000" height="500" src="https://www.youtube-nocookie.com/embed/rJQFLhwYvnA?controls=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></section>
            
            <section>
                
                <h1>Dangers?</h1>
                We have already talked about the limits of rule-following AI. This suggests that the tech is as dangerous as the people who design and use it because there nothing more to it.</section>
<section>One of the best examples of neural networks in AI is Alpha-Go</section>     
        
            
            <section  data-background-image ="img/machine_learning_2x.png" data-background-size = "auto"> </section>            

            <section>This tech is as dangerous as the people who design and use it but also as what "makes up the pile".
            
            <p class="fragment">Let me explain with a concrete example.</p>
            </section>
            

            <section> 
                PULSE is a neural net that takes a low resolution image as input and returns a high resolution image. Like in procedural dramas like CSI!
                </section>

            <section data-background="white" data-background-image="img/pulse.png" data-background-size="contain">
            </section>

            <section>
                
                <h1>BUT</h1>
                
                <p class="fragment">Despite its great sucess in several cases, PULSE can also return an image that a well informed adult would never recognize as a highresolution version of the original. </p>

            </section>

            <section data-background="white" data-background-image="img/gabo.png" data-background-size="contain">
    <p class="fragment highlightred">   
                What kind of error is this?</p> 
            </section>

            

            <section>
                Technology shapes our lives and in that way transmits and strengthens biases. 
                
                <ul>
                
                <li class="fragment">Analog tech has biases. Ex: buildings with accessibility issues.</li>
                    
                                    <li class="fragment">Digital tech has biases. Ex: apps without support for the blind </li>

                </ul>
            </section>


            <section>Neural networks pose an additional problem.</section>
            
                        <section  data-background-image ="img/machine_learning_2x.png" data-background-size = "auto"> </section>            


            <section>PULSE is biased. Where does the bias come from?
            
            <p class="fragment">The inescrutable pile has the answers.</p>
            </section>

            

            <section>
                
                <h1>Dangers?</h1>
               The problem with neural networks comes from the lack of transparency. We are at the mercy of the pile data and statistics. </section>
            
            
            <section data-transition="fade-in" data-background="#009933" data-background-transition="zoom">
                <h3>Next week</h3>
                <ul>
                    <li>Humanity and redemption</li>
                    <ul>
                        <li>Film: Blade Runner</li>
                            <li>Podcast: <a href="https://traffic.libsyn.com/secure/philosophybites/mulhallmixses.mp3">Stephen Mulhall on Film as Philosophy

</a></li>

                            <li>Podcast: <a href="https://traffic.libsyn.com/philosophybites/Lucy_Allais_on_Forgiveness.mp3">Lucy Allais on Forgiveness
</a> </li>

                    </ul>
                </ul>
            </section>

        </div>

    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/zoom/zoom.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/search/search.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
        // Also available as an ES module, see:
        // https://revealjs.com/initialization/
        Reveal.initialize({
            controls: true,
            progress: true,
            center: true,
            hash: true,
            totalTime: 7200, // 1800=30 minutos de tiempo para la totalidad de la presentación//2400=40min

            // Learn about plugins: https://revealjs.com/plugins/
            plugins: [RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight]
        });
    </script>

</body>
</html>
